{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Pupil Labs Neon Recording","text":"<p>Functionality for loading Neon recordings in native recording format</p>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install pupil-labs-neon-recording\n</code></pre> <p>or</p> <pre><code>pip install -e git+https://github.com/pupil-labs/pl-neon-recording.git\n</code></pre>"},{"location":"#documentation","title":"Documentation","text":"<p>Documentation is available at https://pupil-labs.github.io/pl-neon-recording/</p>"},{"location":"#usage","title":"Usage","text":""},{"location":"#basic-usage","title":"Basic Usage","text":"<pre><code>import sys\n\nimport pupil_labs.neon_recording as nr\n\nif len(sys.argv) &lt; 2:\n    print(\"Usage:\")\n    print(\"python basic_usage.py path/to/recording/folder\")\n\n# Open a recording\nrecording = nr.open(sys.argv[1])\n\n# get basic info\nprint(\"Recording Info:\")\nprint(f\"\\tStart time (ns): {recording.start_time}\")\nprint(f\"\\tWearer         : {recording.wearer['name']}\")\nprint(f\"\\tDevice serial  : {recording.device_serial}\")\nprint(f\"\\tGaze samples   : {len(recording.gaze)}\")\nprint(\"\")\n\n# read 10 gaze samples\nprint(\"First 10 gaze samples:\")\ntimestamps = recording.gaze.time[:10]\nsubsample = recording.gaze.sample(timestamps)\nfor gaze_datum in subsample:\n    print(\n        f\"\\t{gaze_datum.time} :\",\n        f\"({gaze_datum.point[0]:0.2f}, {gaze_datum.point[1]:0.2f})\",\n    )\n</code></pre>"},{"location":"#blinks-and-fixations","title":"Blinks And Fixations","text":"<pre><code>import sys\n\nimport cv2\nimport numpy as np\nfrom tqdm import tqdm\n\n# Workaround for https://github.com/opencv/opencv/issues/21952\ncv2.imshow(\"cv/av bug\", np.zeros(1))\ncv2.destroyAllWindows()\n\nimport pupil_labs.neon_recording as nr  # noqa: E402\nfrom pupil_labs.neon_recording import match_ts  # noqa: E402\nfrom pupil_labs.video import Writer  # noqa: E402\n\n\ndef write_text(image, text, x, y):\n    return cv2.putText(\n        image,\n        text,\n        (x, y),\n        cv2.FONT_HERSHEY_SIMPLEX,\n        1,\n        (0, 0, 255),\n        2,\n        cv2.LINE_AA,\n    )\n\n\ndef match_events(target_time, events):\n    # Blink start needs to be &lt;= target_time\n    matches = match_ts(target_time, events.start_time, method=\"backward\")\n\n    # Blink end needs to be &gt;= target_time\n    matches_end = match_ts(target_time, events.stop_time, method=\"forward\")\n\n    matches[np.isnan(matches_end)] = np.nan\n    matches[matches != matches_end] = np.nan\n\n    return matches\n\n\ndef make_overlaid_video(recording_dir, output_video_path):\n    recording = nr.open(recording_dir)\n\n    video_writer = Writer(\n        output_video_path,\n    )\n    video_start_time = recording.eye.time[0]\n\n    blink_matches = match_events(recording.eye.time, recording.blinks)\n    fixation_matches = match_events(recording.eye.time, recording.fixations)\n\n    blink_count = 0\n    fixation_count = 0\n    for frame, blink_index, fixation_index in tqdm(\n        zip(recording.eye, blink_matches, fixation_matches, strict=False),\n        total=len(recording.eye),\n    ):\n        frame_pixels = frame.bgr\n\n        if not np.isnan(blink_index):\n            blink_count = int(blink_index + 1)\n        frame_pixels = write_text(frame_pixels, f\"Blinks: {blink_count}\", 0, 40)\n\n        if not np.isnan(fixation_index):\n            fixation_count = int(fixation_index + 1)\n        frame_pixels = write_text(frame_pixels, f\"Fixations: {fixation_count}\", 0, 80)\n\n        video_time = (frame.time - video_start_time) / 1e9\n        video_writer.write_image(frame_pixels, time=video_time)\n\n        cv2.imshow(\"Frame\", frame_pixels)\n        cv2.pollKey()\n\n    video_writer.close()\n\n\nif __name__ == \"__main__\":\n    make_overlaid_video(sys.argv[1], \"blinks-and-fixations.mp4\")\n</code></pre>"},{"location":"#data-access","title":"Data Access","text":"<pre><code>import sys\nfrom collections.abc import Mapping\nfrom datetime import datetime\n\nimport numpy as np\n\nimport pupil_labs.neon_recording as nr\nfrom pupil_labs.neon_recording.timeseries.timeseries import Timeseries\n\nif len(sys.argv) &lt; 2:\n    print(\"Usage:\")\n    print(\"python basic_usage.py path/to/recording/folder\")\n\n# Open a recording\nrecording = nr.open(sys.argv[1])\n\n\ndef pretty_format(mapping: Mapping):\n    output = []\n    pad = \"    \"\n    keys = mapping.keys()\n    n = max(len(key) for key in keys)\n    for k, v in mapping.items():\n        v_repr_lines = str(v).splitlines()\n        output.append(f\"{pad}{k:&gt;{n}}: {v_repr_lines[0]}\")\n        if len(v_repr_lines) &gt; 1:\n            output.extend(f\"{pad + '  '}{n * ' '}{line}\" for line in v_repr_lines[1:])\n    return \"\\n\".join(output)\n\n\nprint(\"Basic Recording Info:\")\nprint_data = {\n    \"Recording ID\": recording.id,\n    \"Start time (ns since unix epoch)\": f\"{recording.start_time}\",\n    \"Start time (datetime)\": f\"{datetime.fromtimestamp(recording.start_time / 1e9)}\",\n    \"Duration (nanoseconds)\": f\"{recording.duration}\",\n    \"Duration (seconds)\": f\"{recording.duration / 1e9}\",\n    \"Wearer\": f\"{recording.wearer['name']} ({recording.wearer['uuid']})\",\n    \"Device serial\": recording.device_serial,\n    \"App version\": recording.info[\"app_version\"],\n    \"Data format\": recording.info[\"data_format_version\"],\n    \"Gaze Offset\": recording.info[\"gaze_offset\"],\n}\nprint(pretty_format(print_data))\n\nstreams: list[Timeseries] = [\n    recording.gaze,\n    recording.imu,\n    recording.eyeball,\n    recording.pupil,\n    recording.eyelid,\n    recording.blinks,\n    recording.fixations,\n    recording.saccades,\n    recording.worn,\n    recording.eye,\n    recording.scene,\n    recording.audio,\n]\nprint()\nprint(\"Recording streams:\")\nprint(\n    pretty_format({\n        f\"{stream.name} ({len(stream)} samples)\": \"\\n\" + pretty_format(stream[0])\n        for stream in streams\n    })\n)\n\nprint()\nprint(\"Getting data from a stream:\")\n\nprint()\nprint(\"Gaze points\", recording.gaze.point)\n# GazeArray([(1741948698620648018, 966.3677 , 439.58817),\n#            (1741948698630654018, 965.9669 , 441.60403),\n#            (1741948698635648018, 964.2665 , 442.4974 ), ...,\n#            (1741948717448190018, 757.85815, 852.34644),\n#            (1741948717453190018, 766.53174, 857.3709 ),\n#            (1741948717458190018, 730.93604, 851.53723)],\n#           dtype=[('ts', '&lt;i8'), ('x', '&lt;f4'), ('y', '&lt;f4')])\n\nprint()\nprint(\"Gaze timestamps\", recording.gaze.time)\n# array([1741948698620648018, 1741948698630654018, 1741948698635648018, ...,\n#        1741948717448190018, 1741948717453190018, 1741948717458190018])\n\n\n# All stream data can also be accesses as structured numpy arrays and pandas dataframes.\n\nprint()\nprint(\"Gaze data as a structured numpy array:\")\ngaze_np = recording.gaze.data\nprint()\nprint(gaze_np)\n\n\nprint()\nprint(\"Gaze data as pandas dataframe:\")\ngaze_df = recording.gaze.pd\nprint()\nprint(gaze_df)\n\nprint()\nprint(\"Sampling data:\")\n\nprint()\nprint(\"Get closest gaze for scene frames\")\nclosest_gaze_to_scene = recording.gaze.sample(recording.scene.time)\nprint(closest_gaze_to_scene)\nprint(\n    \"closest_gaze_to_scene_times\",\n    (closest_gaze_to_scene.time - recording.start_time) / 1e9,\n)\n\nprint()\nprint(\"Sampled data can be resampled\")\n\nprint()\nprint(\"Closest gaze sampled at 1 fps\")\nclosest_gaze_to_scene_at_one_fps = closest_gaze_to_scene.sample(\n    np.arange(\n        closest_gaze_to_scene.time[0],\n        closest_gaze_to_scene.time[-1],\n        1e9 / 1,\n        dtype=np.int64,\n    ),\n)\nprint(closest_gaze_to_scene_at_one_fps)\nprint(\n    \"closest_gaze_to_scene_at_one_fps_times\",\n    (closest_gaze_to_scene_at_one_fps.time - recording.start_time) / 1e9,\n)\n</code></pre>"},{"location":"#eye-overlay","title":"Eye Overlay","text":"<pre><code>import sys\n\nimport cv2\nimport numpy as np\nfrom tqdm import tqdm\n\n# Workaround for https://github.com/opencv/opencv/issues/21952\ncv2.imshow(\"cv/av bug\", np.zeros(1))\ncv2.destroyAllWindows()\n\nimport pupil_labs.neon_recording as nr  # noqa: E402\nfrom pupil_labs.neon_recording.timeseries.av.video import (  # noqa: E402\n    GrayFrame,\n)\n\n\ndef overlay_image(img, img_overlay, x, y):\n    \"\"\"Overlay `img_overlay` onto `img` at (x, y).\"\"\"\n    # Image ranges\n    y1, y2 = max(0, y), min(img.shape[0], y + img_overlay.shape[0])\n    x1, x2 = max(0, x), min(img.shape[1], x + img_overlay.shape[1])\n\n    # Overlay ranges\n    y1o, y2o = max(0, -y), min(img_overlay.shape[0], img.shape[0] - y)\n    x1o, x2o = max(0, -x), min(img_overlay.shape[1], img.shape[1] - x)\n\n    if y1 &gt;= y2 or x1 &gt;= x2 or y1o &gt;= y2o or x1o &gt;= x2o:\n        return\n\n    img_crop = img[y1:y2, x1:x2]\n    img_overlay_crop = img_overlay[y1o:y2o, x1o:x2o]\n    img_crop[:] = img_overlay_crop\n\n\ndef make_overlaid_video(recording_dir, output_video_path, fps=30):\n    recording = nr.open(recording_dir)\n\n    video_writer = cv2.VideoWriter(\n        str(output_video_path),\n        cv2.VideoWriter_fourcc(*\"MJPG\"),\n        fps,\n        (recording.scene.width, recording.scene.height),\n    )\n\n    output_timestamps = np.arange(\n        recording.scene.time[0], recording.scene.time[-1], int(1e9 / fps)\n    )\n\n    combined_data = zip(\n        output_timestamps,\n        recording.scene.sample(output_timestamps),\n        recording.eye.sample(output_timestamps),\n        strict=False,\n    )\n\n    frame_idx = 0\n    for ts, scene_frame, eye_frame in tqdm(combined_data, total=len(output_timestamps)):\n        frame_idx += 1  # noqa: SIM113\n\n        if abs(scene_frame.time - ts) &lt; 2e9 / fps:\n            frame_pixels = scene_frame.bgr\n        else:\n            # if the video frame timestamp is too far ahead or behind temporally,\n            # replace it with a gray frame\n            frame_pixels = GrayFrame(scene_frame.width, scene_frame.height).bgr\n\n        if abs(eye_frame.time - ts) &lt; 2e9 / fps:\n            eye_pixels = cv2.cvtColor(eye_frame.gray, cv2.COLOR_GRAY2BGR)\n        else:\n            # if the video frame timestamp is too far ahead or behind temporally,\n            # replace it with a gray frame\n            eye_pixels = GrayFrame(eye_frame.width, eye_frame.height).bgr\n\n        overlay_image(frame_pixels, eye_pixels, 50, 50)\n\n        video_writer.write(frame_pixels)\n        cv2.imshow(\"Frame\", frame_pixels)\n        cv2.pollKey()\n\n    video_writer.release()\n\n\nif __name__ == \"__main__\":\n    make_overlaid_video(sys.argv[1], \"eye-overlay-output-video.avi\")\n</code></pre>"},{"location":"#eye-state","title":"Eye State","text":"<pre><code>import sys\n\nimport cv2\nimport numpy as np\nfrom tqdm import tqdm\n\n# Workaround for https://github.com/opencv/opencv/issues/21952\ncv2.imshow(\"cv/av bug\", np.zeros(1))\ncv2.destroyAllWindows()\n\nimport pupil_labs.neon_recording as nr  # noqa: E402\nfrom pupil_labs.video import Writer  # noqa: E402\n\n\ndef overlay_image(img, img_overlay, x, y):\n    \"\"\"Overlay `img_overlay` onto `img` at (x, y).\"\"\"\n    # Image ranges\n    y1, y2 = max(0, y), min(img.shape[0], y + img_overlay.shape[0])\n    x1, x2 = max(0, x), min(img.shape[1], x + img_overlay.shape[1])\n\n    # Overlay ranges\n    y1o, y2o = max(0, -y), min(img_overlay.shape[0], img.shape[0] - y)\n    x1o, x2o = max(0, -x), min(img_overlay.shape[1], img.shape[1] - x)\n\n    if y1 &gt;= y2 or x1 &gt;= x2 or y1o &gt;= y2o or x1o &gt;= x2o:\n        return\n\n    img_crop = img[y1:y2, x1:x2]\n    img_overlay_crop = img_overlay[y1o:y2o, x1o:x2o]\n    img_crop[:] = img_overlay_crop\n\n\ndef plot(img, data, value_range, x_width, color, line_width=2):\n    for idx in range(1, len(data)):\n        x_values = [int(idx2 * x_width) for idx2 in [idx - 1, idx]]\n\n        y_norms = [\n            (data[idx2] - value_range[0]) / (value_range[1] - value_range[0])\n            for idx2 in [idx - 1, idx]\n        ]\n        y_values = [int(y_norm * img.shape[0]) for y_norm in y_norms]\n\n        points = [[*v] for v in zip(x_values, y_values, strict=False)]\n\n        cv2.line(img, points[0], points[1], color, line_width)\n\n\ndef make_eye_state_video(recording_dir, output_video_path):\n    recording = nr.open(recording_dir)\n\n    fps = 200\n    video_writer = Writer(output_video_path)\n    video_start_time = recording.eye.time[0]\n\n    plot_config = [\n        {\"color\": [0, 0, 255]},\n        {\"color\": [0, 255, 0]},\n        {\"color\": [255, 0, 0]},\n    ]\n\n    for dim, config in enumerate(plot_config):\n        config[\"range\"] = (\n            np.min(recording.eyeball.optical_axis_left[:, dim]),\n            np.max(recording.eyeball.optical_axis_left[:, dim]),\n        )\n\n    plot_duration_secs = 0.5\n    plot_point_count = plot_duration_secs * fps\n    plot_x_width = recording.eye.width / plot_point_count\n\n    for eye_sample in tqdm(recording.eye):\n        eye_pixels = eye_sample.bgr\n\n        for dim, config in enumerate(plot_config):\n            min_ts = eye_sample.time - plot_duration_secs * 1e9\n            mask = (min_ts &lt; recording.eyeball.time) &amp; (\n                recording.eyeball.time &lt;= eye_sample.time\n            )\n            plot_data = recording.eyeball.optical_axis_left[mask, dim]\n            plot(\n                eye_pixels,\n                plot_data,\n                config[\"range\"],\n                plot_x_width,\n                config[\"color\"],\n            )\n\n        video_time = (eye_sample.time - video_start_time) / 1e9\n        video_writer.write_image(eye_pixels, time=video_time)\n        cv2.imshow(\"Frame\", eye_pixels)\n        cv2.pollKey()\n\n    video_writer.close()\n\n\nif __name__ == \"__main__\":\n    make_eye_state_video(sys.argv[1], \"eye-state-output-video.avi\")\n</code></pre>"},{"location":"#find-clap","title":"Find Clap","text":"<pre><code>import sys\n\nimport numpy as np\nfrom tqdm import tqdm\n\nimport pupil_labs.neon_recording as nr\n\n\ndef find_clap(recording_dir, window_size_seconds=0.1, first_n_seconds=10):\n    recording = nr.open(recording_dir)\n\n    audio_data = np.array([], dtype=np.float32)\n    ts_lookup = []\n    for frame in recording.audio:\n        if first_n_seconds is not None:\n            rel_time = (frame.time - recording.start_time) / 1e9\n            if rel_time &gt; first_n_seconds:\n                break\n\n        # Create a timestamp lookup table\n        ts_lookup.append([len(audio_data), frame.time])\n\n        # Gather all the audio samples\n        audio_data = np.concatenate((audio_data, frame.to_ndarray().flatten()))\n\n    ts_lookup = np.array(ts_lookup)\n\n    # Calculate RMS over a sliding window\n    # Remember the sample index of the loudest window\n    max_rms = 0\n    loudest_sample_idx = 0\n\n    samples_per_window = int(window_size_seconds * recording.audio.rate)\n    for i in tqdm(range(len(audio_data) - samples_per_window)):\n        segment = audio_data[i : i + samples_per_window]\n        rms = np.sqrt(np.mean(np.square(segment)))\n\n        if rms &gt; max_rms:\n            max_rms = rms\n            loudest_sample_idx = int(i + samples_per_window / 2)\n\n    # Find the reference timestamp from the lookup table\n    lookup_idx = np.searchsorted(ts_lookup[:, 0], loudest_sample_idx) - 1\n    reference_ts = ts_lookup[lookup_idx, 1]\n\n    # Calculate the sample timestamp using the reference timestamp\n    samples_after_reference = loudest_sample_idx - ts_lookup[lookup_idx, 0]\n    loudest_time = reference_ts + (samples_after_reference / recording.audio.rate) * 1e9\n\n    print(f\"The loudest audio occurs at {loudest_time:.0f} rms = {max_rms:.3f}.\")\n    print(\n        f\"    Relative to recording start: \"\n        f\"{(loudest_time - recording.start_time) / 1e9:0.3f}s\"\n    )\n    print(\n        f\"    Relative to video start    : \"\n        f\"{(loudest_time - recording.scene.time[0]) / 1e9:0.3f}s\"\n    )\n    print(\n        f\"    Relative to audio start    : \"\n        f\"{(loudest_time - recording.audio.time[0]) / 1e9:0.3f}s\"\n    )\n\n\nif __name__ == \"__main__\":\n    find_clap(sys.argv[1])\n</code></pre>"},{"location":"#gaze-overlay","title":"Gaze Overlay","text":"<pre><code>import sys\n\nimport cv2\nimport numpy as np\nfrom tqdm import tqdm\n\n# Workaround for https://github.com/opencv/opencv/issues/21952\ncv2.imshow(\"cv/av bug\", np.zeros(1))\ncv2.destroyAllWindows()\n\nimport pupil_labs.neon_recording as nr  # noqa: E402\nfrom pupil_labs.video import Writer  # noqa: E402\n\n\ndef make_overlaid_video(recording_dir, output_video_path):\n    rec = nr.open(recording_dir)\n\n    combined_data = zip(\n        rec.scene,\n        rec.gaze.sample(rec.scene.time),\n        strict=True,\n    )\n\n    video_writer = Writer(output_video_path)\n    video_start_time = rec.scene.time[0]\n\n    for scene_frame, gaze_datum in tqdm(combined_data, total=len(rec.scene.time)):\n        frame_pixels = scene_frame.bgr\n\n        frame_pixels = cv2.circle(\n            frame_pixels,\n            (int(gaze_datum.point[0]), int(gaze_datum.point[1])),\n            50,\n            (0, 0, 255),\n            10,\n        )\n\n        video_time = (scene_frame.time - video_start_time) / 1e9\n        video_writer.write_image(frame_pixels, time=video_time)\n\n        cv2.imshow(\"Frame\", frame_pixels)\n        cv2.waitKey(30)\n\n    video_writer.close()\n\n\nif __name__ == \"__main__\":\n    make_overlaid_video(sys.argv[1], \"gaze-overlay-output-video.mp4\")\n</code></pre>"},{"location":"#imu","title":"Imu","text":"<pre><code>import sys\n\nimport cv2\nimport numpy as np\nfrom scipy.spatial.transform import Rotation\nfrom tqdm import tqdm\n\n# Workaround for https://github.com/opencv/opencv/issues/21952\ncv2.imshow(\"cv/av bug\", np.zeros(1))\ncv2.destroyAllWindows()\n\nimport pupil_labs.neon_recording as nr  # noqa: E402\n\nif len(sys.argv) &lt; 2:\n    print(\"Usage:\")\n    print(\"python imu.py path/to/recording/folder\")\n\n# Open a recording\nrecording = nr.open(sys.argv[1])\n\n# Sample the IMU data at 60Hz\nfps = 60\nz = recording.gaze[:10]\ntimestamps = np.arange(\n    recording.imu.time[0], recording.imu.time[-1], 1e9 / fps, dtype=np.int64\n)\nimu_data = recording.imu.sample(timestamps)\n\n# Use scipy to convert the quaternions to euler angles\nquaternions = np.array([s.rotation for s in imu_data])\nrotations = Rotation.from_quat(quaternions).as_euler(seq=\"yxz\", degrees=True) % 360\n\n# Combine the timestamps and eulers\nrotations_with_time = np.column_stack((timestamps, rotations))\ntimestamped_eulers = np.array(\n    [tuple(row) for row in rotations_with_time],\n    dtype=[\n        (\"time\", np.int64),\n        (\"roll\", np.float64),\n        (\"pitch\", np.float64),\n        (\"yaw\", np.float64),\n    ],\n)\n\n# Display the angles\nframe_size = 512\ncolors = {\"pitch\": (0, 0, 255), \"yaw\": (0, 255, 0), \"roll\": (255, 0, 0)}\n\nfor row in tqdm(timestamped_eulers):\n    # Create a blank image\n    frame = np.zeros((frame_size, frame_size, 3), dtype=np.uint8)\n\n    # Define the center and radius of the circles\n    center = [frame_size // 2] * 2\n    radius = frame.shape[0] // 3\n\n    # Calculate the end points for the angles\n    for field, color in colors.items():\n        pitch_end = (\n            int(center[0] + radius * np.cos(np.deg2rad(row[field]))),\n            int(center[1] - radius * np.sin(np.deg2rad(row[field]))),\n        )\n        cv2.line(frame, center, pitch_end, color, 2)\n\n        # Write the angle values on the image\n        cv2.putText(\n            frame,\n            f\"{field}: {row[field]:.2f}\",\n            (10, 30 + list(colors.keys()).index(field) * 30),\n            cv2.FONT_HERSHEY_SIMPLEX,\n            0.7,\n            color,\n            2,\n        )\n\n    # Display the image\n    cv2.imshow(\"IMU Angles\", frame)\n    if cv2.waitKey(1000 // fps) == 27:\n        break\n\ncv2.destroyAllWindows()\n</code></pre>"},{"location":"#worn","title":"Worn","text":"<pre><code>import sys\n\nimport cv2\nimport numpy as np\nfrom tqdm import tqdm\n\n# Workaround for https://github.com/opencv/opencv/issues/21952\ncv2.imshow(\"cv/av bug\", np.zeros(1))\ncv2.destroyAllWindows()\n\nfrom pupil_labs import neon_recording as nr  # noqa: E402\n\n\ndef write_text(image, text, x, y):\n    return cv2.putText(\n        image,\n        text,\n        (x, y),\n        cv2.FONT_HERSHEY_SIMPLEX,\n        1,\n        (0, 0, 255),\n        2,\n        cv2.LINE_AA,\n    )\n\n\ndef make_overlaid_video(recording_dir, output_video_path, fps=30):\n    recording = nr.open(recording_dir)\n\n    video_writer = cv2.VideoWriter(\n        str(output_video_path),\n        cv2.VideoWriter_fourcc(*\"MJPG\"),\n        fps,\n        (recording.eye.width, recording.eye.height),\n    )\n\n    output_timestamps = np.arange(\n        recording.eye.time[0], recording.eye.time[-1], int(1e9 / fps)\n    )\n    eyes_and_worn = zip(\n        recording.eye.sample(output_timestamps),\n        recording.worn.sample(output_timestamps),\n        strict=False,\n    )\n\n    for frame, worn_record in tqdm(eyes_and_worn, total=len(output_timestamps)):\n        frame_pixels = frame.bgr\n\n        text_y = 40\n        if worn_record.worn:\n            frame_pixels = write_text(frame_pixels, \"Worn\", 0, text_y)\n\n        video_writer.write(frame_pixels)\n        cv2.imshow(\"Frame\", frame_pixels)\n        cv2.pollKey()\n\n    video_writer.release()\n\n\nif __name__ == \"__main__\":\n    make_overlaid_video(sys.argv[1], \"worn.mp4\")\n</code></pre>"},{"location":"license/","title":"License","text":"<pre><code>MIT License\n\nCopyright (c) 2025 Pupil Labs GmbH\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n</code></pre>"},{"location":"modules/","title":"API reference","text":""},{"location":"modules/#pupil_labs.neon_recording","title":"neon_recording","text":"<p>Modules:</p> <ul> <li> <code>calib</code>           \u2013            <p>Camera calibration utils</p> </li> <li> <code>neon_recording</code>           \u2013            <p>Neon Recording</p> </li> <li> <code>timeseries</code>           \u2013            </li> </ul> <p>Classes:</p> <ul> <li> <code>AudioTimeseries</code>           \u2013            <p>Audio frames</p> </li> <li> <code>BlinkTimeseries</code>           \u2013            <p>Blink event data.</p> </li> <li> <code>EventTimeseries</code>           \u2013            <p>Event annotations</p> </li> <li> <code>FixationTimeseries</code>           \u2013            <p>Fixation event data.</p> </li> <li> <code>IMUTimeseries</code>           \u2013            <p>Motion and orientation data</p> </li> <li> <code>NeonRecording</code>           \u2013            <p>Class to handle the Neon Recording data</p> </li> <li> <code>Timeseries</code>           \u2013            <p>Base class for all Neon timeseries data.</p> </li> <li> <code>VideoTimeseries</code>           \u2013            <p>Video frames from a camera</p> </li> </ul> <p>Functions:</p> <ul> <li> <code>open</code>             \u2013              <p>Load a NeonRecording from a path</p> </li> </ul>"},{"location":"modules/#pupil_labs.neon_recording.AudioTimeseries","title":"AudioTimeseries","text":"<pre><code>AudioTimeseries(recording: NeonRecording, data: ArrayType | None = None)\n</code></pre> <p>               Bases: <code>BaseAVTimeseries</code></p> <p>Audio frames</p> <p>Attributes:</p> <ul> <li> <code>data</code>           \u2013            <p>Data as a numpy array</p> </li> <li> <code>pd</code>           \u2013            <p>Data as a pandas DataFrame</p> </li> <li> <code>time</code>           \u2013            <p>The moment these data were recorded</p> </li> </ul> Source code in <code>src/pupil_labs/neon_recording/timeseries/timeseries.py</code> <pre><code>def __init__(self, recording: \"NeonRecording\", data: ArrayType | None = None):\n    self.recording = recording\n    if data is None:\n        data = self._load_data_from_recording(recording)\n    self._data = data\n</code></pre>"},{"location":"modules/#pupil_labs.neon_recording.AudioTimeseries.data","title":"data  <code>property</code>","text":"<pre><code>data\n</code></pre> <p>Data as a numpy array</p>"},{"location":"modules/#pupil_labs.neon_recording.AudioTimeseries.pd","title":"pd  <code>property</code>","text":"<pre><code>pd\n</code></pre> <p>Data as a pandas DataFrame</p>"},{"location":"modules/#pupil_labs.neon_recording.AudioTimeseries.time","title":"time  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>time = fields[int64](TIMESTAMP_FIELD_NAME)\n</code></pre> <p>The moment these data were recorded</p>"},{"location":"modules/#pupil_labs.neon_recording.BlinkTimeseries","title":"BlinkTimeseries","text":"<pre><code>BlinkTimeseries(recording: NeonRecording, data: ArrayType | None = None)\n</code></pre> <p>               Bases: <code>Timeseries[BlinkArray, BlinkRecord]</code>, <code>BlinkProps</code></p> <p>Blink event data.</p> <p>Attributes:</p> <ul> <li> <code>data</code>           \u2013            <p>Data as a numpy array</p> </li> <li> <code>pd</code>           \u2013            <p>Data as a pandas DataFrame</p> </li> <li> <code>start_time</code>           \u2013            <p>Start timestamp of the blink.</p> </li> <li> <code>stop_time</code>           \u2013            <p>Stop timestamp of the blink.</p> </li> <li> <code>time</code>           \u2013            <p>The moment these data were recorded</p> </li> </ul> Source code in <code>src/pupil_labs/neon_recording/timeseries/timeseries.py</code> <pre><code>def __init__(self, recording: \"NeonRecording\", data: ArrayType | None = None):\n    self.recording = recording\n    if data is None:\n        data = self._load_data_from_recording(recording)\n    self._data = data\n</code></pre>"},{"location":"modules/#pupil_labs.neon_recording.BlinkTimeseries.data","title":"data  <code>property</code>","text":"<pre><code>data\n</code></pre> <p>Data as a numpy array</p>"},{"location":"modules/#pupil_labs.neon_recording.BlinkTimeseries.pd","title":"pd  <code>property</code>","text":"<pre><code>pd\n</code></pre> <p>Data as a pandas DataFrame</p>"},{"location":"modules/#pupil_labs.neon_recording.BlinkTimeseries.start_time","title":"start_time  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>start_time = fields[int64]('start_time')\n</code></pre> <p>Start timestamp of the blink.</p>"},{"location":"modules/#pupil_labs.neon_recording.BlinkTimeseries.stop_time","title":"stop_time  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>stop_time = fields[int64]('stop_time')\n</code></pre> <p>Stop timestamp of the blink.</p>"},{"location":"modules/#pupil_labs.neon_recording.BlinkTimeseries.time","title":"time  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>time = fields[int64](TIMESTAMP_FIELD_NAME)\n</code></pre> <p>The moment these data were recorded</p>"},{"location":"modules/#pupil_labs.neon_recording.EventTimeseries","title":"EventTimeseries","text":"<pre><code>EventTimeseries(recording: NeonRecording, data: ArrayType | None = None)\n</code></pre> <p>               Bases: <code>Timeseries[EventArray, EventRecord]</code>, <code>EventProps</code></p> <p>Event annotations</p> <p>Attributes:</p> <ul> <li> <code>by_name</code>           \u2013            <p>Return a dict of event_name =&gt; all ts</p> </li> <li> <code>data</code>           \u2013            <p>Data as a numpy array</p> </li> <li> <code>event</code>               (<code>NDArray[str_]</code>)           \u2013            <p>Event name</p> </li> <li> <code>pd</code>           \u2013            <p>Data as a pandas DataFrame</p> </li> <li> <code>time</code>           \u2013            <p>The moment these data were recorded</p> </li> </ul> Source code in <code>src/pupil_labs/neon_recording/timeseries/timeseries.py</code> <pre><code>def __init__(self, recording: \"NeonRecording\", data: ArrayType | None = None):\n    self.recording = recording\n    if data is None:\n        data = self._load_data_from_recording(recording)\n    self._data = data\n</code></pre>"},{"location":"modules/#pupil_labs.neon_recording.EventTimeseries.by_name","title":"by_name  <code>cached</code> <code>property</code>","text":"<pre><code>by_name\n</code></pre> <p>Return a dict of event_name =&gt; all ts</p>"},{"location":"modules/#pupil_labs.neon_recording.EventTimeseries.data","title":"data  <code>property</code>","text":"<pre><code>data\n</code></pre> <p>Data as a numpy array</p>"},{"location":"modules/#pupil_labs.neon_recording.EventTimeseries.event","title":"event  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>event: NDArray[str_] = fields[str_]('event')\n</code></pre> <p>Event name</p>"},{"location":"modules/#pupil_labs.neon_recording.EventTimeseries.pd","title":"pd  <code>property</code>","text":"<pre><code>pd\n</code></pre> <p>Data as a pandas DataFrame</p>"},{"location":"modules/#pupil_labs.neon_recording.EventTimeseries.time","title":"time  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>time = fields[int64](TIMESTAMP_FIELD_NAME)\n</code></pre> <p>The moment these data were recorded</p>"},{"location":"modules/#pupil_labs.neon_recording.FixationTimeseries","title":"FixationTimeseries","text":"<pre><code>FixationTimeseries(recording: NeonRecording, data: ArrayType | None = None)\n</code></pre> <p>               Bases: <code>Timeseries[FixationArray, FixationRecord]</code>, <code>FixationProps</code></p> <p>Fixation event data.</p> <p>Attributes:</p> <ul> <li> <code>data</code>           \u2013            <p>Data as a numpy array</p> </li> <li> <code>mean_gaze_point</code>           \u2013            <p>Mean gaze position in pixels. Note that this value may be a poor representation</p> </li> <li> <code>pd</code>           \u2013            <p>Data as a pandas DataFrame</p> </li> <li> <code>start_gaze_point</code>           \u2013            <p>Start gaze position in pixels.</p> </li> <li> <code>start_time</code>           \u2013            <p>Start timestamp of fixation.</p> </li> <li> <code>stop_gaze_point</code>           \u2013            <p>Stop gaze position in pixels.</p> </li> <li> <code>stop_time</code>           \u2013            <p>Stop timestamp of fixation.</p> </li> <li> <code>time</code>           \u2013            <p>The moment these data were recorded</p> </li> </ul> Source code in <code>src/pupil_labs/neon_recording/timeseries/timeseries.py</code> <pre><code>def __init__(self, recording: \"NeonRecording\", data: ArrayType | None = None):\n    self.recording = recording\n    if data is None:\n        data = self._load_data_from_recording(recording)\n    self._data = data\n</code></pre>"},{"location":"modules/#pupil_labs.neon_recording.FixationTimeseries.data","title":"data  <code>property</code>","text":"<pre><code>data\n</code></pre> <p>Data as a numpy array</p>"},{"location":"modules/#pupil_labs.neon_recording.FixationTimeseries.mean_gaze_point","title":"mean_gaze_point  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>mean_gaze_point = fields[float32](['mean_gaze_x', 'mean_gaze_y'])\n</code></pre> <p>Mean gaze position in pixels. Note that this value may be a poor representation of the fixation in the presence of VOR movements.</p>"},{"location":"modules/#pupil_labs.neon_recording.FixationTimeseries.pd","title":"pd  <code>property</code>","text":"<pre><code>pd\n</code></pre> <p>Data as a pandas DataFrame</p>"},{"location":"modules/#pupil_labs.neon_recording.FixationTimeseries.start_gaze_point","title":"start_gaze_point  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>start_gaze_point = fields[float32](['start_gaze_x', 'start_gaze_y'])\n</code></pre> <p>Start gaze position in pixels.</p>"},{"location":"modules/#pupil_labs.neon_recording.FixationTimeseries.start_time","title":"start_time  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>start_time = fields[int64]('start_time')\n</code></pre> <p>Start timestamp of fixation.</p>"},{"location":"modules/#pupil_labs.neon_recording.FixationTimeseries.stop_gaze_point","title":"stop_gaze_point  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>stop_gaze_point = fields[float32](['stop_gaze_x', 'stop_gaze_y'])\n</code></pre> <p>Stop gaze position in pixels.</p>"},{"location":"modules/#pupil_labs.neon_recording.FixationTimeseries.stop_time","title":"stop_time  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>stop_time = fields[int64]('stop_time')\n</code></pre> <p>Stop timestamp of fixation.</p>"},{"location":"modules/#pupil_labs.neon_recording.FixationTimeseries.time","title":"time  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>time = fields[int64](TIMESTAMP_FIELD_NAME)\n</code></pre> <p>The moment these data were recorded</p>"},{"location":"modules/#pupil_labs.neon_recording.IMUTimeseries","title":"IMUTimeseries","text":"<pre><code>IMUTimeseries(recording: NeonRecording, data: ArrayType | None = None)\n</code></pre> <p>               Bases: <code>Timeseries[ImuArray, ImuRecord]</code>, <code>ImuProps</code></p> <p>Motion and orientation data</p> <p>Attributes:</p> <ul> <li> <code>acceleration</code>           \u2013            <p>Translational acceleration data.</p> </li> <li> <code>angular_velocity</code>           \u2013            <p>Angular velocity data.</p> </li> <li> <code>data</code>           \u2013            <p>Data as a numpy array</p> </li> <li> <code>pd</code>           \u2013            <p>Data as a pandas DataFrame</p> </li> <li> <code>rotation</code>           \u2013            <p>Rotation as a quaternion given as <code>xyzw</code>.</p> </li> <li> <code>time</code>           \u2013            <p>The moment these data were recorded</p> </li> </ul> Source code in <code>src/pupil_labs/neon_recording/timeseries/timeseries.py</code> <pre><code>def __init__(self, recording: \"NeonRecording\", data: ArrayType | None = None):\n    self.recording = recording\n    if data is None:\n        data = self._load_data_from_recording(recording)\n    self._data = data\n</code></pre>"},{"location":"modules/#pupil_labs.neon_recording.IMUTimeseries.acceleration","title":"acceleration  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>acceleration = fields[float64](['acceleration_x', 'acceleration_y', 'acceleration_z'])\n</code></pre> <p>Translational acceleration data.</p>"},{"location":"modules/#pupil_labs.neon_recording.IMUTimeseries.angular_velocity","title":"angular_velocity  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>angular_velocity = fields[float64](['angular_velocity_x', 'angular_velocity_y', 'angular_velocity_z'])\n</code></pre> <p>Angular velocity data.</p>"},{"location":"modules/#pupil_labs.neon_recording.IMUTimeseries.data","title":"data  <code>property</code>","text":"<pre><code>data\n</code></pre> <p>Data as a numpy array</p>"},{"location":"modules/#pupil_labs.neon_recording.IMUTimeseries.pd","title":"pd  <code>property</code>","text":"<pre><code>pd\n</code></pre> <p>Data as a pandas DataFrame</p>"},{"location":"modules/#pupil_labs.neon_recording.IMUTimeseries.rotation","title":"rotation  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>rotation = fields[float64](['quaternion_x', 'quaternion_y', 'quaternion_z', 'quaternion_w'])\n</code></pre> <p>Rotation as a quaternion given as <code>xyzw</code>.</p>"},{"location":"modules/#pupil_labs.neon_recording.IMUTimeseries.time","title":"time  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>time = fields[int64](TIMESTAMP_FIELD_NAME)\n</code></pre> <p>The moment these data were recorded</p>"},{"location":"modules/#pupil_labs.neon_recording.NeonRecording","title":"NeonRecording","text":"<pre><code>NeonRecording(rec_dir_in: Path | str)\n</code></pre> <p>Class to handle the Neon Recording data</p> <p>Parameters:</p> <ul> <li> <code>rec_dir_in</code>               (<code>Path | str</code>)           \u2013            <p>Path to the recording directory.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>FileNotFoundError</code>             \u2013            <p>If the directory does not exist or is not valid.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>audio</code>               (<code>AudioTimeseries</code>)           \u2013            <p>Audio from the scene video</p> </li> <li> <code>blinks</code>               (<code>BlinkTimeseries</code>)           \u2013            <p>Blink data</p> </li> <li> <code>calibration</code>               (<code>Calibration | None</code>)           \u2013            <p>Device camera calibration data</p> </li> <li> <code>device_serial</code>               (<code>str | None</code>)           \u2013            <p>Device serial number</p> </li> <li> <code>duration</code>               (<code>int</code>)           \u2013            <p>Recording Duration (nanoseconds)</p> </li> <li> <code>events</code>               (<code>EventTimeseries</code>)           \u2013            <p>Event annotations</p> </li> <li> <code>eye</code>               (<code>EyeVideoTimeseries</code>)           \u2013            <p>Frames of video from the eye cameras</p> </li> <li> <code>eyeball</code>               (<code>EyeballTimeseries</code>)           \u2013            <p>Eye state data</p> </li> <li> <code>eyelid</code>               (<code>EyelidTimeseries</code>)           \u2013            <p>Eyelid data</p> </li> <li> <code>fixations</code>               (<code>FixationTimeseries</code>)           \u2013            <p>Fixations data</p> </li> <li> <code>gaze</code>               (<code>GazeTimeseries</code>)           \u2013            <p>2D gaze data in scene-camera space</p> </li> <li> <code>id</code>               (<code>str | None</code>)           \u2013            <p>UUID of the recording</p> </li> <li> <code>imu</code>               (<code>IMUTimeseries</code>)           \u2013            <p>Motion and orientation data</p> </li> <li> <code>info</code>               (<code>dict</code>)           \u2013            <p>Information loaded from info.json</p> </li> <li> <code>pupil</code>               (<code>PupilTimeseries</code>)           \u2013            <p>Pupil diameter data</p> </li> <li> <code>saccades</code>               (<code>SaccadeTimeseries</code>)           \u2013            <p>Saccades data</p> </li> <li> <code>scene</code>               (<code>SceneVideoTimeseries</code>)           \u2013            <p>Frames of video from the scene camera</p> </li> <li> <code>start_time</code>               (<code>int</code>)           \u2013            <p>Start timestamp (nanoseconds since 1970-01-01)</p> </li> <li> <code>stop_time</code>               (<code>int</code>)           \u2013            <p>Stop timestamp (nanoseconds since 1970-01-01)</p> </li> <li> <code>wearer</code>               (<code>dict</code>)           \u2013            <p>Wearer information containing uuid and name</p> </li> <li> <code>worn</code>               (<code>WornTimeseries</code>)           \u2013            <p>Worn (headset on/off) data</p> </li> </ul> Source code in <code>src/pupil_labs/neon_recording/neon_recording.py</code> <pre><code>def __init__(self, rec_dir_in: pathlib.Path | str):\n    \"\"\"Initialize the NeonRecording object\n\n    Args:\n        rec_dir_in: Path to the recording directory.\n\n    Raises:\n        FileNotFoundError: If the directory does not exist or is not valid.\n\n    \"\"\"\n    self._rec_dir = UPath(rec_dir_in).resolve()\n    if not self._rec_dir.exists() or not self._rec_dir.is_dir():\n        raise FileNotFoundError(\n            f\"Directory not found or not valid: {self._rec_dir}\"\n        )\n</code></pre>"},{"location":"modules/#pupil_labs.neon_recording.NeonRecording.audio","title":"audio  <code>cached</code> <code>property</code>","text":"<pre><code>audio: AudioTimeseries\n</code></pre> <p>Audio from the scene video</p>"},{"location":"modules/#pupil_labs.neon_recording.NeonRecording.blinks","title":"blinks  <code>cached</code> <code>property</code>","text":"<pre><code>blinks: BlinkTimeseries\n</code></pre> <p>Blink data</p>"},{"location":"modules/#pupil_labs.neon_recording.NeonRecording.calibration","title":"calibration  <code>cached</code> <code>property</code>","text":"<pre><code>calibration: Calibration | None\n</code></pre> <p>Device camera calibration data</p>"},{"location":"modules/#pupil_labs.neon_recording.NeonRecording.device_serial","title":"device_serial  <code>property</code>","text":"<pre><code>device_serial: str | None\n</code></pre> <p>Device serial number</p>"},{"location":"modules/#pupil_labs.neon_recording.NeonRecording.duration","title":"duration  <code>property</code>","text":"<pre><code>duration: int\n</code></pre> <p>Recording Duration (nanoseconds)</p>"},{"location":"modules/#pupil_labs.neon_recording.NeonRecording.events","title":"events  <code>cached</code> <code>property</code>","text":"<pre><code>events: EventTimeseries\n</code></pre> <p>Event annotations</p>"},{"location":"modules/#pupil_labs.neon_recording.NeonRecording.eye","title":"eye  <code>cached</code> <code>property</code>","text":"<pre><code>eye: EyeVideoTimeseries\n</code></pre> <p>Frames of video from the eye cameras</p>"},{"location":"modules/#pupil_labs.neon_recording.NeonRecording.eyeball","title":"eyeball  <code>cached</code> <code>property</code>","text":"<pre><code>eyeball: EyeballTimeseries\n</code></pre> <p>Eye state data</p>"},{"location":"modules/#pupil_labs.neon_recording.NeonRecording.eyelid","title":"eyelid  <code>cached</code> <code>property</code>","text":"<pre><code>eyelid: EyelidTimeseries\n</code></pre> <p>Eyelid data</p>"},{"location":"modules/#pupil_labs.neon_recording.NeonRecording.fixations","title":"fixations  <code>cached</code> <code>property</code>","text":"<pre><code>fixations: FixationTimeseries\n</code></pre> <p>Fixations data</p>"},{"location":"modules/#pupil_labs.neon_recording.NeonRecording.gaze","title":"gaze  <code>cached</code> <code>property</code>","text":"<pre><code>gaze: GazeTimeseries\n</code></pre> <p>2D gaze data in scene-camera space</p>"},{"location":"modules/#pupil_labs.neon_recording.NeonRecording.id","title":"id  <code>property</code>","text":"<pre><code>id: str | None\n</code></pre> <p>UUID of the recording</p>"},{"location":"modules/#pupil_labs.neon_recording.NeonRecording.imu","title":"imu  <code>cached</code> <code>property</code>","text":"<pre><code>imu: IMUTimeseries\n</code></pre> <p>Motion and orientation data</p>"},{"location":"modules/#pupil_labs.neon_recording.NeonRecording.info","title":"info  <code>cached</code> <code>property</code>","text":"<pre><code>info: dict\n</code></pre> <p>Information loaded from info.json</p>"},{"location":"modules/#pupil_labs.neon_recording.NeonRecording.pupil","title":"pupil  <code>cached</code> <code>property</code>","text":"<pre><code>pupil: PupilTimeseries\n</code></pre> <p>Pupil diameter data</p>"},{"location":"modules/#pupil_labs.neon_recording.NeonRecording.saccades","title":"saccades  <code>cached</code> <code>property</code>","text":"<pre><code>saccades: SaccadeTimeseries\n</code></pre> <p>Saccades data</p>"},{"location":"modules/#pupil_labs.neon_recording.NeonRecording.scene","title":"scene  <code>cached</code> <code>property</code>","text":"<pre><code>scene: SceneVideoTimeseries\n</code></pre> <p>Frames of video from the scene camera</p>"},{"location":"modules/#pupil_labs.neon_recording.NeonRecording.start_time","title":"start_time  <code>property</code>","text":"<pre><code>start_time: int\n</code></pre> <p>Start timestamp (nanoseconds since 1970-01-01)</p>"},{"location":"modules/#pupil_labs.neon_recording.NeonRecording.stop_time","title":"stop_time  <code>property</code>","text":"<pre><code>stop_time: int\n</code></pre> <p>Stop timestamp (nanoseconds since 1970-01-01)</p>"},{"location":"modules/#pupil_labs.neon_recording.NeonRecording.wearer","title":"wearer  <code>cached</code> <code>property</code>","text":"<pre><code>wearer: dict\n</code></pre> <p>Wearer information containing uuid and name</p>"},{"location":"modules/#pupil_labs.neon_recording.NeonRecording.worn","title":"worn  <code>cached</code> <code>property</code>","text":"<pre><code>worn: WornTimeseries\n</code></pre> <p>Worn (headset on/off) data</p>"},{"location":"modules/#pupil_labs.neon_recording.Timeseries","title":"Timeseries","text":"<pre><code>Timeseries(recording: NeonRecording, data: ArrayType | None = None)\n</code></pre> <p>               Bases: <code>TimeseriesProps</code>, <code>Generic[ArrayType, RecordType]</code></p> <p>Base class for all Neon timeseries data.</p> <p>Attributes:</p> <ul> <li> <code>data</code>           \u2013            <p>Data as a numpy array</p> </li> <li> <code>pd</code>           \u2013            <p>Data as a pandas DataFrame</p> </li> <li> <code>time</code>           \u2013            <p>The moment these data were recorded</p> </li> </ul> Source code in <code>src/pupil_labs/neon_recording/timeseries/timeseries.py</code> <pre><code>def __init__(self, recording: \"NeonRecording\", data: ArrayType | None = None):\n    self.recording = recording\n    if data is None:\n        data = self._load_data_from_recording(recording)\n    self._data = data\n</code></pre>"},{"location":"modules/#pupil_labs.neon_recording.Timeseries.data","title":"data  <code>property</code>","text":"<pre><code>data\n</code></pre> <p>Data as a numpy array</p>"},{"location":"modules/#pupil_labs.neon_recording.Timeseries.pd","title":"pd  <code>property</code>","text":"<pre><code>pd\n</code></pre> <p>Data as a pandas DataFrame</p>"},{"location":"modules/#pupil_labs.neon_recording.Timeseries.time","title":"time  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>time = fields[int64](TIMESTAMP_FIELD_NAME)\n</code></pre> <p>The moment these data were recorded</p>"},{"location":"modules/#pupil_labs.neon_recording.VideoTimeseries","title":"VideoTimeseries","text":"<pre><code>VideoTimeseries(recording: NeonRecording, data: ArrayType | None = None)\n</code></pre> <p>               Bases: <code>BaseAVTimeseries</code></p> <p>Video frames from a camera</p> <p>Attributes:</p> <ul> <li> <code>data</code>           \u2013            <p>Data as a numpy array</p> </li> <li> <code>height</code>               (<code>int | None</code>)           \u2013            <p>Height of the video</p> </li> <li> <code>pd</code>           \u2013            <p>Data as a pandas DataFrame</p> </li> <li> <code>time</code>           \u2013            <p>The moment these data were recorded</p> </li> <li> <code>width</code>               (<code>int | None</code>)           \u2013            <p>Width of the video</p> </li> </ul> Source code in <code>src/pupil_labs/neon_recording/timeseries/timeseries.py</code> <pre><code>def __init__(self, recording: \"NeonRecording\", data: ArrayType | None = None):\n    self.recording = recording\n    if data is None:\n        data = self._load_data_from_recording(recording)\n    self._data = data\n</code></pre>"},{"location":"modules/#pupil_labs.neon_recording.VideoTimeseries.data","title":"data  <code>property</code>","text":"<pre><code>data\n</code></pre> <p>Data as a numpy array</p>"},{"location":"modules/#pupil_labs.neon_recording.VideoTimeseries.height","title":"height  <code>cached</code> <code>property</code>","text":"<pre><code>height: int | None\n</code></pre> <p>Height of the video</p>"},{"location":"modules/#pupil_labs.neon_recording.VideoTimeseries.pd","title":"pd  <code>property</code>","text":"<pre><code>pd\n</code></pre> <p>Data as a pandas DataFrame</p>"},{"location":"modules/#pupil_labs.neon_recording.VideoTimeseries.time","title":"time  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>time = fields[int64](TIMESTAMP_FIELD_NAME)\n</code></pre> <p>The moment these data were recorded</p>"},{"location":"modules/#pupil_labs.neon_recording.VideoTimeseries.width","title":"width  <code>cached</code> <code>property</code>","text":"<pre><code>width: int | None\n</code></pre> <p>Width of the video</p>"},{"location":"modules/#pupil_labs.neon_recording.open","title":"open","text":"<pre><code>open(rec_dir_in: Path | str) -&gt; NeonRecording\n</code></pre> <p>Load a NeonRecording from a path</p> Source code in <code>src/pupil_labs/neon_recording/neon_recording.py</code> <pre><code>def open(rec_dir_in: pathlib.Path | str) -&gt; NeonRecording:  # noqa: A001\n    \"\"\"Load a NeonRecording from a path\"\"\"\n    return NeonRecording(rec_dir_in)\n</code></pre>"},{"location":"coverage/","title":"Coverage","text":""}]}