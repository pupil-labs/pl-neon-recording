{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Pupil Labs Neon Recording","text":"<p>Functionality for loading Neon recordings in native recording format</p>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install pupil-labs-neon-recording\n</code></pre> <p>or</p> <pre><code>pip install -e git+https://github.com/pupil-labs/pl-neon-recording.git\n</code></pre>"},{"location":"contributing/","title":"Developer","text":""},{"location":"license/","title":"License","text":"<pre><code>---\ntitle: MIT License\nspdx-id: MIT\nfeatured: true\nhidden: false\n\ndescription: A short and simple permissive license with conditions only requiring preservation of copyright and license notices. Licensed works, modifications, and larger works may be distributed under different terms and without source code.\n\nhow: Create a text file (typically named LICENSE or LICENSE.txt) in the root of your source code and copy the text of the license into the file. Replace [year] with the current year and [fullname] with the name (or names) of the copyright holders.\n\nusing:\n  Babel: https://github.com/babel/babel/blob/master/LICENSE\n  .NET: https://github.com/dotnet/runtime/blob/main/LICENSE.TXT\n  Rails: https://github.com/rails/rails/blob/master/MIT-LICENSE\n\npermissions:\n  - commercial-use\n  - modifications\n  - distribution\n  - private-use\n\nconditions:\n  - include-copyright\n\nlimitations:\n  - liability\n  - warranty\n\n---\n\nMIT License\n\nCopyright (c) 2025 Pupil Labs GmbH\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n</code></pre>"},{"location":"modules/","title":"API reference","text":""},{"location":"modules/#pupil_labs.neon_recording","title":"neon_recording","text":"<p>Modules:</p> <ul> <li> <code>calib</code>           \u2013            <p>Camera calibration utils</p> </li> <li> <code>neon_recording</code>           \u2013            <p>Neon Recording</p> </li> <li> <code>stream</code>           \u2013            <p>Streams module</p> </li> </ul> <p>Classes:</p> <ul> <li> <code>AudioStream</code>           \u2013            <p>Audio frames stream</p> </li> <li> <code>BlinkStream</code>           \u2013            <p>Blink data</p> </li> <li> <code>EventStream</code>           \u2013            <p>Event annotations</p> </li> <li> <code>EyeStateStream</code>           \u2013            <p>Eye state data</p> </li> <li> <code>FixationStream</code>           \u2013            <p>Fixation data</p> </li> <li> <code>GazeStream</code>           \u2013            <p>Gaze data</p> </li> <li> <code>IMUStream</code>           \u2013            <p>Motion and orientation data</p> </li> <li> <code>NeonRecording</code>           \u2013            <p>Class to handle the Neon Recording data</p> </li> <li> <code>VideoStream</code>           \u2013            <p>Video frames from a camera</p> </li> <li> <code>WornStream</code>           \u2013            <p>Worn (headset on/off) data</p> </li> </ul> <p>Functions:</p> <ul> <li> <code>load</code>             \u2013              <p>Load a NeonRecording from a path</p> </li> </ul>"},{"location":"modules/#pupil_labs.neon_recording.AudioStream","title":"AudioStream","text":"<pre><code>AudioStream(name: str, base_name: str, recording: NeonRecording)\n</code></pre> <p>               Bases: <code>BaseAVStream</code></p> <p>Audio frames stream</p> <p>Attributes:</p> <ul> <li> <code>ts</code>           \u2013            <p>The moment these data were recorded</p> </li> </ul> Source code in <code>src/pupil_labs/neon_recording/stream/av_stream/base_av_stream.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    base_name: str,\n    recording: \"NeonRecording\",\n):\n    self.name = name\n    self._base_name = base_name\n    self.recording = recording\n\n    log.debug(f\"NeonRecording: Loading video: {self._base_name}.\")\n\n    self.video_parts: list[plv.Reader[plv.VideoFrame]] = []\n    av_files = find_sorted_multipart_files(\n        self.recording._rec_dir, self._base_name, \".mp4\"\n    )\n    parts_ts = []\n    video_readers = []\n    for av_file, time_file in av_files:\n        if self.kind == \"video\":\n            part_ts = Array(time_file, dtype=TIMESTAMP_DTYPE)\n            container_timestamps = (part_ts[\"ts\"] - recording.start_ts) / 1e9\n            reader = plv.Reader(str(av_file), self.kind, container_timestamps)\n            part_ts = part_ts[: len(reader)]\n        elif self.kind == \"audio\":\n            reader = plv.Reader(str(av_file), self.kind)\n            part_ts = (\n                recording.start_ts + (reader.container_timestamps * 1e9)\n            ).astype(TIMESTAMP_DTYPE)\n        else:\n            raise RuntimeError(f\"unknown av stream kind: {self.kind}\")\n\n        parts_ts.append(part_ts)\n        video_readers.append(reader)\n\n    parts_ts = np.concatenate(parts_ts)\n\n    data = join_struct_arrays(\n        [\n            parts_ts,\n            np.arange(len(parts_ts)).view(AV_INDEX_DTYPE),\n        ],\n    )\n    self.av_reader = plv.MultiReader(video_readers)\n\n    BoundAVFrameClass = type(\n        f\"{self.name.capitalize()}Frame\",\n        (BaseAVStreamFrame,),\n        dict(dtype=data.dtype, multi_video_reader=self.av_reader),\n    )\n    BoundAVFramesClass = type(\n        f\"{self.name.capitalize()}Frames\",\n        (Array,),\n        dict(\n            record_class=BoundAVFrameClass,\n            dtype=data.dtype,\n            multi_video_reader=self.av_reader,\n        ),\n    )\n\n    super().__init__(name, recording, data.view(BoundAVFramesClass))\n</code></pre>"},{"location":"modules/#pupil_labs.neon_recording.AudioStream.ts","title":"ts  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ts = fields[int64](TIMESTAMP_FIELD_NAME)\n</code></pre> <p>The moment these data were recorded</p>"},{"location":"modules/#pupil_labs.neon_recording.BlinkStream","title":"BlinkStream","text":"<pre><code>BlinkStream(recording: NeonRecording)\n</code></pre> <p>               Bases: <code>Stream[BlinkRecord]</code>, <code>BlinkProps</code></p> <p>Blink data</p> <p>Attributes:</p> <ul> <li> <code>end_ts</code>           \u2013            <p>End timestamp of blink</p> </li> <li> <code>start_ts</code>           \u2013            <p>Start timestamp of blink</p> </li> <li> <code>ts</code>           \u2013            <p>The moment these data were recorded</p> </li> </ul> Source code in <code>src/pupil_labs/neon_recording/stream/blink_stream.py</code> <pre><code>def __init__(self, recording: \"NeonRecording\"):\n    log.debug(\"NeonRecording: Loading blink data\")\n    file_pairs = find_sorted_multipart_files(recording._rec_dir, \"blinks\")\n    data = load_multipart_data_time_pairs(\n        file_pairs,\n        np.dtype([\n            (\"start_timestamp_ns\", \"int64\"),\n            (\"end_timestamp_ns\", \"int64\"),\n        ]),\n    )\n    super().__init__(\"blink\", recording, data.view(BlinkArray))\n</code></pre>"},{"location":"modules/#pupil_labs.neon_recording.BlinkStream.end_ts","title":"end_ts  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>end_ts = fields[int64]('end_timestamp_ns')\n</code></pre> <p>End timestamp of blink</p>"},{"location":"modules/#pupil_labs.neon_recording.BlinkStream.start_ts","title":"start_ts  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>start_ts = fields[int64]('start_timestamp_ns')\n</code></pre> <p>Start timestamp of blink</p>"},{"location":"modules/#pupil_labs.neon_recording.BlinkStream.ts","title":"ts  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ts = fields[int64](TIMESTAMP_FIELD_NAME)\n</code></pre> <p>The moment these data were recorded</p>"},{"location":"modules/#pupil_labs.neon_recording.EventStream","title":"EventStream","text":"<pre><code>EventStream(recording)\n</code></pre> <p>               Bases: <code>Stream</code></p> <p>Event annotations</p> Each record contains <ul> <li><code>ts</code>: The moment these data were recorded</li> <li><code>event</code>: The name of the event</li> </ul> <p>Attributes:</p> <ul> <li> <code>ts</code>           \u2013            <p>The moment these data were recorded</p> </li> </ul> Source code in <code>src/pupil_labs/neon_recording/stream/event_stream.py</code> <pre><code>def __init__(self, recording):\n    log.debug(\"NeonRecording: Loading event data\")\n\n    events_file = recording._rec_dir / \"event.txt\"\n    time_file = events_file.with_suffix(\".time\")\n    file_pairs = []\n    if events_file.exists and time_file.exists():\n        file_pairs = [(events_file, time_file)]\n    data = load_multipart_data_time_pairs(file_pairs, \"str\")\n    data.dtype.names = [\n        \"event\" if name == \"text\" else name for name in data.dtype.names\n    ]\n    super().__init__(\"event\", recording, data)\n</code></pre>"},{"location":"modules/#pupil_labs.neon_recording.EventStream.ts","title":"ts  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ts = fields[int64](TIMESTAMP_FIELD_NAME)\n</code></pre> <p>The moment these data were recorded</p>"},{"location":"modules/#pupil_labs.neon_recording.EyeStateStream","title":"EyeStateStream","text":"<pre><code>EyeStateStream(recording: NeonRecording)\n</code></pre> <p>               Bases: <code>Stream[EyeStateRecord]</code>, <code>EyeStateProps</code></p> <p>Eye state data</p> <p>Attributes:</p> <ul> <li> <code>eyeball_center_left_xyz</code>           \u2013            <p>The xyz position in mm of the left eyeball relative to the scene camera</p> </li> <li> <code>eyeball_center_right_xyz</code>           \u2013            <p>The xyz position in mm of the right eyeball relative to the scene camera</p> </li> <li> <code>eyelid_angle</code>           \u2013            <p>Eyelid angle: (top_left, bottom_left, top_right, bottom_right)</p> </li> <li> <code>eyelid_aperture_left_right_mm</code>           \u2013            <p>Eyelid aperture in mm: (left, right)</p> </li> <li> <code>optical_axis_left_xyz</code>           \u2013            <p>A xyz vector in the forward direction of the left eye's optical axis</p> </li> <li> <code>optical_axis_right_xyz</code>           \u2013            <p>A xyz vector in the forward direction of the right eye's optical axis</p> </li> <li> <code>pupil_diameter_left_right_mm</code>           \u2013            <p>Pupil diameter (in mm) for both eyes: (left, right)</p> </li> <li> <code>ts</code>           \u2013            <p>The moment these data were recorded</p> </li> </ul> Source code in <code>src/pupil_labs/neon_recording/stream/eye_state_stream.py</code> <pre><code>def __init__(self, recording: \"NeonRecording\"):\n    log.debug(\"NeonRecording: Loading eye state data\")\n    file_pairs = find_sorted_multipart_files(recording._rec_dir, \"eye_state\")\n    data = load_multipart_data_time_pairs(\n        file_pairs,\n        dtype=np.dtype([\n            (\"pupil_diameter_left_mm\", \"float32\"),\n            (\"eyeball_center_left_x\", \"float32\"),\n            (\"eyeball_center_left_y\", \"float32\"),\n            (\"eyeball_center_left_z\", \"float32\"),\n            (\"optical_axis_left_x\", \"float32\"),\n            (\"optical_axis_left_y\", \"float32\"),\n            (\"optical_axis_left_z\", \"float32\"),\n            (\"pupil_diameter_right_mm\", \"float32\"),\n            (\"eyeball_center_right_x\", \"float32\"),\n            (\"eyeball_center_right_y\", \"float32\"),\n            (\"eyeball_center_right_z\", \"float32\"),\n            (\"optical_axis_right_x\", \"float32\"),\n            (\"optical_axis_right_y\", \"float32\"),\n            (\"optical_axis_right_z\", \"float32\"),\n        ]),\n    )\n    super().__init__(\"eye_state\", recording, data.view(EyeStateArray))\n</code></pre>"},{"location":"modules/#pupil_labs.neon_recording.EyeStateStream.eyeball_center_left_xyz","title":"eyeball_center_left_xyz  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>eyeball_center_left_xyz = fields[float64](['eyeball_center_left_x', 'eyeball_center_left_y', 'eyeball_center_left_z'])\n</code></pre> <p>The xyz position in mm of the left eyeball relative to the scene camera</p>"},{"location":"modules/#pupil_labs.neon_recording.EyeStateStream.eyeball_center_right_xyz","title":"eyeball_center_right_xyz  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>eyeball_center_right_xyz = fields[float64](['eyeball_center_right_x', 'eyeball_center_right_y', 'eyeball_center_right_z'])\n</code></pre> <p>The xyz position in mm of the right eyeball relative to the scene camera</p>"},{"location":"modules/#pupil_labs.neon_recording.EyeStateStream.eyelid_angle","title":"eyelid_angle  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>eyelid_angle = fields[float64](['eyelid_angle_top_left', 'eyelid_angle_bottom_left', 'eyelid_angle_top_right', 'eyelid_angle_bottom_right'])\n</code></pre> <p>Eyelid angle: (top_left, bottom_left, top_right, bottom_right)</p>"},{"location":"modules/#pupil_labs.neon_recording.EyeStateStream.eyelid_aperture_left_right_mm","title":"eyelid_aperture_left_right_mm  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>eyelid_aperture_left_right_mm = fields[float64](['eyelid_aperture_left_mm', 'eyelid_aperture_right_mm'])\n</code></pre> <p>Eyelid aperture in mm: (left, right)</p>"},{"location":"modules/#pupil_labs.neon_recording.EyeStateStream.optical_axis_left_xyz","title":"optical_axis_left_xyz  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>optical_axis_left_xyz = fields[float64](['optical_axis_left_x', 'optical_axis_left_y', 'optical_axis_left_z'])\n</code></pre> <p>A xyz vector in the forward direction of the left eye's optical axis</p>"},{"location":"modules/#pupil_labs.neon_recording.EyeStateStream.optical_axis_right_xyz","title":"optical_axis_right_xyz  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>optical_axis_right_xyz = fields[float64](['optical_axis_right_x', 'optical_axis_right_y', 'optical_axis_right_z'])\n</code></pre> <p>A xyz vector in the forward direction of the right eye's optical axis</p>"},{"location":"modules/#pupil_labs.neon_recording.EyeStateStream.pupil_diameter_left_right_mm","title":"pupil_diameter_left_right_mm  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>pupil_diameter_left_right_mm = fields[float64](['pupil_diameter_left_mm', 'pupil_diameter_right_mm'])\n</code></pre> <p>Pupil diameter (in mm) for both eyes: (left, right)</p>"},{"location":"modules/#pupil_labs.neon_recording.EyeStateStream.ts","title":"ts  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ts = fields[int64](TIMESTAMP_FIELD_NAME)\n</code></pre> <p>The moment these data were recorded</p>"},{"location":"modules/#pupil_labs.neon_recording.FixationStream","title":"FixationStream","text":"<pre><code>FixationStream(recording: NeonRecording)\n</code></pre> <p>               Bases: <code>Stream[FixationRecord]</code>, <code>FixationProps</code></p> <p>Fixation data</p> <p>Attributes:</p> <ul> <li> <code>amplitude_angle_deg</code>           \u2013            <p>Amplitude angle (degrees)</p> </li> <li> <code>amplitude_pixels</code>           \u2013            <p>Amplitude (pixels)</p> </li> <li> <code>end_gaze_xy</code>           \u2013            <p>End gaze position in pixels</p> </li> <li> <code>end_ts</code>           \u2013            <p>Start timestamp of fixation</p> </li> <li> <code>event_type</code>           \u2013            <p>Fixation event kind (0 = saccade / 1 = fixation)</p> </li> <li> <code>max_velocity</code>           \u2013            <p>Max velocity of fixation (pixels/sec)</p> </li> <li> <code>mean_gaze_xy</code>           \u2013            <p>Mean gaze position in pixels</p> </li> <li> <code>mean_velocity</code>           \u2013            <p>Mean velocity of fixation (pixels/sec)</p> </li> <li> <code>start_gaze_xy</code>           \u2013            <p>Start gaze position in pixels</p> </li> <li> <code>start_ts</code>           \u2013            <p>Start timestamp of fixation</p> </li> <li> <code>ts</code>           \u2013            <p>The moment these data were recorded</p> </li> </ul> Source code in <code>src/pupil_labs/neon_recording/stream/fixation_stream.py</code> <pre><code>def __init__(self, recording: \"NeonRecording\"):\n    log.debug(\"NeonRecording: Loading fixation data\")\n    file_pairs = find_sorted_multipart_files(recording._rec_dir, \"fixations\")\n    data = load_multipart_data_time_pairs(\n        file_pairs,\n        np.dtype([\n            (\"event_type\", \"int32\"),\n            (\"start_timestamp_ns\", \"int64\"),\n            (\"end_timestamp_ns\", \"int64\"),\n            (\"start_gaze_x\", \"float32\"),\n            (\"start_gaze_y\", \"float32\"),\n            (\"end_gaze_x\", \"float32\"),\n            (\"end_gaze_y\", \"float32\"),\n            (\"mean_gaze_x\", \"float32\"),\n            (\"mean_gaze_y\", \"float32\"),\n            (\"amplitude_pixels\", \"float32\"),\n            (\"amplitude_angle_deg\", \"float32\"),\n            (\"mean_velocity\", \"float32\"),\n            (\"max_velocity\", \"float32\"),\n        ]),\n    )\n    super().__init__(\"fixation\", recording, data.view(FixationArray))\n</code></pre>"},{"location":"modules/#pupil_labs.neon_recording.FixationStream.amplitude_angle_deg","title":"amplitude_angle_deg  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>amplitude_angle_deg = fields[float32]('amplitude_angle_deg')\n</code></pre> <p>Amplitude angle (degrees)</p>"},{"location":"modules/#pupil_labs.neon_recording.FixationStream.amplitude_pixels","title":"amplitude_pixels  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>amplitude_pixels = fields[float32]('amplitude_pixels')\n</code></pre> <p>Amplitude (pixels)</p>"},{"location":"modules/#pupil_labs.neon_recording.FixationStream.end_gaze_xy","title":"end_gaze_xy  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>end_gaze_xy = fields[float32](['end_gaze_x', 'end_gaze_y'])\n</code></pre> <p>End gaze position in pixels</p>"},{"location":"modules/#pupil_labs.neon_recording.FixationStream.end_ts","title":"end_ts  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>end_ts = fields[int64]('end_timestamp_ns')\n</code></pre> <p>Start timestamp of fixation</p>"},{"location":"modules/#pupil_labs.neon_recording.FixationStream.event_type","title":"event_type  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>event_type = fields[int32]('event_type')\n</code></pre> <p>Fixation event kind (0 = saccade / 1 = fixation)</p>"},{"location":"modules/#pupil_labs.neon_recording.FixationStream.max_velocity","title":"max_velocity  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>max_velocity = fields[float32]('max_velocity')\n</code></pre> <p>Max velocity of fixation (pixels/sec)</p>"},{"location":"modules/#pupil_labs.neon_recording.FixationStream.mean_gaze_xy","title":"mean_gaze_xy  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>mean_gaze_xy = fields[float32](['mean_gaze_x', 'mean_gaze_y'])\n</code></pre> <p>Mean gaze position in pixels</p>"},{"location":"modules/#pupil_labs.neon_recording.FixationStream.mean_velocity","title":"mean_velocity  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>mean_velocity = fields[float32]('mean_velocity')\n</code></pre> <p>Mean velocity of fixation (pixels/sec)</p>"},{"location":"modules/#pupil_labs.neon_recording.FixationStream.start_gaze_xy","title":"start_gaze_xy  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>start_gaze_xy = fields[float32](['start_gaze_x', 'start_gaze_y'])\n</code></pre> <p>Start gaze position in pixels</p>"},{"location":"modules/#pupil_labs.neon_recording.FixationStream.start_ts","title":"start_ts  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>start_ts = fields[int64]('start_timestamp_ns')\n</code></pre> <p>Start timestamp of fixation</p>"},{"location":"modules/#pupil_labs.neon_recording.FixationStream.ts","title":"ts  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ts = fields[int64](TIMESTAMP_FIELD_NAME)\n</code></pre> <p>The moment these data were recorded</p>"},{"location":"modules/#pupil_labs.neon_recording.GazeStream","title":"GazeStream","text":"<pre><code>GazeStream(recording: NeonRecording)\n</code></pre> <p>               Bases: <code>Stream[GazeRecord]</code>, <code>GazeProps</code></p> <p>Gaze data</p> <p>Attributes:</p> <ul> <li> <code>ts</code>           \u2013            <p>The moment these data were recorded</p> </li> <li> <code>x</code>           \u2013            <p>Gaze x coordinate in pixels</p> </li> <li> <code>xy</code>           \u2013            <p>Gaze xy coordinates in pixels</p> </li> <li> <code>y</code>           \u2013            <p>Gaze y coordinate in pixels</p> </li> </ul> Source code in <code>src/pupil_labs/neon_recording/stream/gaze_stream.py</code> <pre><code>def __init__(self, recording: \"NeonRecording\"):\n    log.debug(\"NeonRecording: Loading gaze data\")\n\n    gaze_200hz_file = recording._rec_dir / \"gaze_200hz.raw\"\n    time_200hz_file = recording._rec_dir / \"gaze_200hz.time\"\n\n    file_pairs = []\n    if gaze_200hz_file.exists() and time_200hz_file.exists():\n        log.debug(\"NeonRecording: Using 200Hz gaze data\")\n        file_pairs.append((gaze_200hz_file, time_200hz_file))\n    else:\n        log.debug(\"NeonRecording: Using realtime gaze data\")\n        file_pairs = find_sorted_multipart_files(recording._rec_dir, \"gaze\")\n\n    data = load_multipart_data_time_pairs(\n        file_pairs,\n        np.dtype([\n            (\"x\", \"float32\"),\n            (\"y\", \"float32\"),\n        ]),\n    )\n    super().__init__(\"gaze\", recording, data.view(GazeArray))\n</code></pre>"},{"location":"modules/#pupil_labs.neon_recording.GazeStream.ts","title":"ts  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ts = fields[int64](TIMESTAMP_FIELD_NAME)\n</code></pre> <p>The moment these data were recorded</p>"},{"location":"modules/#pupil_labs.neon_recording.GazeStream.x","title":"x  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>x = fields[float64]('x')\n</code></pre> <p>Gaze x coordinate in pixels</p>"},{"location":"modules/#pupil_labs.neon_recording.GazeStream.xy","title":"xy  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>xy = fields[float64](['x', 'y'])\n</code></pre> <p>Gaze xy coordinates in pixels</p>"},{"location":"modules/#pupil_labs.neon_recording.GazeStream.y","title":"y  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>y = fields[float64]('y')\n</code></pre> <p>Gaze y coordinate in pixels</p>"},{"location":"modules/#pupil_labs.neon_recording.IMUStream","title":"IMUStream","text":"<pre><code>IMUStream(recording)\n</code></pre> <p>               Bases: <code>Stream</code></p> <p>Motion and orientation data</p> <p>Attributes:</p> <ul> <li> <code>ts</code>           \u2013            <p>The moment these data were recorded</p> </li> </ul> Source code in <code>src/pupil_labs/neon_recording/stream/imu/imu_stream.py</code> <pre><code>def __init__(self, recording):\n    log.debug(\"NeonRecording: Loading IMU data\")\n\n    imu_file_pairs = find_sorted_multipart_files(recording._rec_dir, \"imu\")\n\n    if len(imu_file_pairs) &gt; 0:\n        imu_data = Array(\n            [file for file, _ in imu_file_pairs],\n            fallback_dtype=np.dtype(IMUStream.FALLBACK_DTYPE),\n        )\n        imu_data.dtype.names = [\n            TIMESTAMP_FIELD_NAME if name == \"timestamp_ns\" else name\n            for name in imu_data.dtype.names\n        ]\n\n    else:\n        imu_file_pairs = find_sorted_multipart_files(recording._rec_dir, \"extimu\")\n        time_data = Array([file for _, file in imu_file_pairs], TIMESTAMP_DTYPE)\n\n        records = []\n        for imu_file, _ in imu_file_pairs:\n            with imu_file.open(\"rb\") as raw_file:\n                raw_data = raw_file.read()\n                imu_packets = parse_neon_imu_raw_packets(raw_data)\n\n                for packet in imu_packets:\n                    records.append((\n                        packet.gyroData.x,\n                        packet.gyroData.y,\n                        packet.gyroData.z,\n                        packet.accelData.x,\n                        packet.accelData.y,\n                        packet.accelData.z,\n                        packet.rotVecData.w,\n                        packet.rotVecData.x,\n                        packet.rotVecData.y,\n                        packet.rotVecData.z,\n                    ))\n\n        imu_data = np.array(records, dtype=IMUStream.FALLBACK_DTYPE)\n        imu_data = join_struct_arrays([time_data, imu_data])\n\n    super().__init__(\"imu\", recording, imu_data.view(ImuArray))\n</code></pre>"},{"location":"modules/#pupil_labs.neon_recording.IMUStream.ts","title":"ts  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ts = fields[int64](TIMESTAMP_FIELD_NAME)\n</code></pre> <p>The moment these data were recorded</p>"},{"location":"modules/#pupil_labs.neon_recording.NeonRecording","title":"NeonRecording","text":"<pre><code>NeonRecording(rec_dir_in: Union[Path, str])\n</code></pre> <p>Class to handle the Neon Recording data</p> <p>Parameters:</p> <ul> <li> <code>rec_dir_in</code>               (<code>Union[Path, str]</code>)           \u2013            <p>Path to the recording directory.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>FileNotFoundError</code>             \u2013            <p>If the directory does not exist or is not valid.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>audio</code>               (<code>AudioStream</code>)           \u2013            <p>Audio from the scene video</p> </li> <li> <code>blinks</code>               (<code>BlinkStream</code>)           \u2013            <p>Blink data</p> </li> <li> <code>calibration</code>               (<code>Calibration | None</code>)           \u2013            <p>Device camera calibration data</p> </li> <li> <code>device_serial</code>               (<code>str | None</code>)           \u2013            <p>Device serial number</p> </li> <li> <code>duration</code>               (<code>int | None</code>)           \u2013            <p>Recording Duration (nanoseconds)</p> </li> <li> <code>events</code>               (<code>EventStream</code>)           \u2013            <p>Event annotations</p> </li> <li> <code>eye</code>               (<code>VideoStream</code>)           \u2013            <p>Frames of video from the eye cameras</p> </li> <li> <code>eye_state</code>               (<code>EyeStateStream</code>)           \u2013            <p>Eye state data</p> </li> <li> <code>fixations</code>               (<code>FixationStream</code>)           \u2013            <p>Fixations data</p> </li> <li> <code>gaze</code>               (<code>GazeStream</code>)           \u2013            <p>2D gaze data in scene-camera space</p> </li> <li> <code>imu</code>               (<code>IMUStream</code>)           \u2013            <p>Motion and orientation data</p> </li> <li> <code>info</code>               (<code>dict</code>)           \u2013            <p>Information loaded from info.json</p> </li> <li> <code>scene</code>               (<code>VideoStream</code>)           \u2013            <p>Frames of video from the scene camera</p> </li> <li> <code>start_ts</code>               (<code>int | None</code>)           \u2013            <p>Start timestamp (nanoseconds since 1970-01-01)</p> </li> <li> <code>wearer</code>               (<code>dict</code>)           \u2013            <p>Wearer information containing uuid and name</p> </li> <li> <code>worn</code>               (<code>WornStream</code>)           \u2013            <p>Worn (headset on/off) data</p> </li> </ul> Source code in <code>src/pupil_labs/neon_recording/neon_recording.py</code> <pre><code>def __init__(self, rec_dir_in: Union[pathlib.Path, str]):\n    \"\"\"Initialize the NeonRecording object\n\n    Args:\n        rec_dir_in: Path to the recording directory.\n\n    Raises:\n        FileNotFoundError: If the directory does not exist or is not valid.\n\n    \"\"\"\n    self._rec_dir = pathlib.Path(rec_dir_in).resolve()\n    if not self._rec_dir.exists() or not self._rec_dir.is_dir():\n        raise FileNotFoundError(\n            f\"Directory not found or not valid: {self._rec_dir}\"\n        )\n</code></pre>"},{"location":"modules/#pupil_labs.neon_recording.NeonRecording.audio","title":"audio  <code>cached</code> <code>property</code>","text":"<pre><code>audio: AudioStream\n</code></pre> <p>Audio from the scene video</p>"},{"location":"modules/#pupil_labs.neon_recording.NeonRecording.blinks","title":"blinks  <code>cached</code> <code>property</code>","text":"<pre><code>blinks: BlinkStream\n</code></pre> <p>Blink data</p>"},{"location":"modules/#pupil_labs.neon_recording.NeonRecording.calibration","title":"calibration  <code>cached</code> <code>property</code>","text":"<pre><code>calibration: Calibration | None\n</code></pre> <p>Device camera calibration data</p>"},{"location":"modules/#pupil_labs.neon_recording.NeonRecording.device_serial","title":"device_serial  <code>property</code>","text":"<pre><code>device_serial: str | None\n</code></pre> <p>Device serial number</p>"},{"location":"modules/#pupil_labs.neon_recording.NeonRecording.duration","title":"duration  <code>property</code>","text":"<pre><code>duration: int | None\n</code></pre> <p>Recording Duration (nanoseconds)</p>"},{"location":"modules/#pupil_labs.neon_recording.NeonRecording.events","title":"events  <code>cached</code> <code>property</code>","text":"<pre><code>events: EventStream\n</code></pre> <p>Event annotations</p>"},{"location":"modules/#pupil_labs.neon_recording.NeonRecording.eye","title":"eye  <code>cached</code> <code>property</code>","text":"<pre><code>eye: VideoStream\n</code></pre> <p>Frames of video from the eye cameras</p>"},{"location":"modules/#pupil_labs.neon_recording.NeonRecording.eye_state","title":"eye_state  <code>cached</code> <code>property</code>","text":"<pre><code>eye_state: EyeStateStream\n</code></pre> <p>Eye state data</p>"},{"location":"modules/#pupil_labs.neon_recording.NeonRecording.fixations","title":"fixations  <code>cached</code> <code>property</code>","text":"<pre><code>fixations: FixationStream\n</code></pre> <p>Fixations data</p>"},{"location":"modules/#pupil_labs.neon_recording.NeonRecording.gaze","title":"gaze  <code>cached</code> <code>property</code>","text":"<pre><code>gaze: GazeStream\n</code></pre> <p>2D gaze data in scene-camera space</p>"},{"location":"modules/#pupil_labs.neon_recording.NeonRecording.imu","title":"imu  <code>cached</code> <code>property</code>","text":"<pre><code>imu: IMUStream\n</code></pre> <p>Motion and orientation data</p>"},{"location":"modules/#pupil_labs.neon_recording.NeonRecording.info","title":"info  <code>cached</code> <code>property</code>","text":"<pre><code>info: dict\n</code></pre> <p>Information loaded from info.json</p>"},{"location":"modules/#pupil_labs.neon_recording.NeonRecording.scene","title":"scene  <code>cached</code> <code>property</code>","text":"<pre><code>scene: VideoStream\n</code></pre> <p>Frames of video from the scene camera</p>"},{"location":"modules/#pupil_labs.neon_recording.NeonRecording.start_ts","title":"start_ts  <code>property</code>","text":"<pre><code>start_ts: int | None\n</code></pre> <p>Start timestamp (nanoseconds since 1970-01-01)</p>"},{"location":"modules/#pupil_labs.neon_recording.NeonRecording.wearer","title":"wearer  <code>cached</code> <code>property</code>","text":"<pre><code>wearer: dict\n</code></pre> <p>Wearer information containing uuid and name</p>"},{"location":"modules/#pupil_labs.neon_recording.NeonRecording.worn","title":"worn  <code>cached</code> <code>property</code>","text":"<pre><code>worn: WornStream\n</code></pre> <p>Worn (headset on/off) data</p>"},{"location":"modules/#pupil_labs.neon_recording.VideoStream","title":"VideoStream","text":"<pre><code>VideoStream(name: str, base_name: str, recording: NeonRecording)\n</code></pre> <p>               Bases: <code>BaseAVStream</code></p> <p>Video frames from a camera</p> <p>Attributes:</p> <ul> <li> <code>height</code>               (<code>int | None</code>)           \u2013            <p>Height of image in stream</p> </li> <li> <code>ts</code>           \u2013            <p>The moment these data were recorded</p> </li> <li> <code>width</code>               (<code>int | None</code>)           \u2013            <p>Width of image in stream</p> </li> </ul> Source code in <code>src/pupil_labs/neon_recording/stream/av_stream/base_av_stream.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    base_name: str,\n    recording: \"NeonRecording\",\n):\n    self.name = name\n    self._base_name = base_name\n    self.recording = recording\n\n    log.debug(f\"NeonRecording: Loading video: {self._base_name}.\")\n\n    self.video_parts: list[plv.Reader[plv.VideoFrame]] = []\n    av_files = find_sorted_multipart_files(\n        self.recording._rec_dir, self._base_name, \".mp4\"\n    )\n    parts_ts = []\n    video_readers = []\n    for av_file, time_file in av_files:\n        if self.kind == \"video\":\n            part_ts = Array(time_file, dtype=TIMESTAMP_DTYPE)\n            container_timestamps = (part_ts[\"ts\"] - recording.start_ts) / 1e9\n            reader = plv.Reader(str(av_file), self.kind, container_timestamps)\n            part_ts = part_ts[: len(reader)]\n        elif self.kind == \"audio\":\n            reader = plv.Reader(str(av_file), self.kind)\n            part_ts = (\n                recording.start_ts + (reader.container_timestamps * 1e9)\n            ).astype(TIMESTAMP_DTYPE)\n        else:\n            raise RuntimeError(f\"unknown av stream kind: {self.kind}\")\n\n        parts_ts.append(part_ts)\n        video_readers.append(reader)\n\n    parts_ts = np.concatenate(parts_ts)\n\n    data = join_struct_arrays(\n        [\n            parts_ts,\n            np.arange(len(parts_ts)).view(AV_INDEX_DTYPE),\n        ],\n    )\n    self.av_reader = plv.MultiReader(video_readers)\n\n    BoundAVFrameClass = type(\n        f\"{self.name.capitalize()}Frame\",\n        (BaseAVStreamFrame,),\n        dict(dtype=data.dtype, multi_video_reader=self.av_reader),\n    )\n    BoundAVFramesClass = type(\n        f\"{self.name.capitalize()}Frames\",\n        (Array,),\n        dict(\n            record_class=BoundAVFrameClass,\n            dtype=data.dtype,\n            multi_video_reader=self.av_reader,\n        ),\n    )\n\n    super().__init__(name, recording, data.view(BoundAVFramesClass))\n</code></pre>"},{"location":"modules/#pupil_labs.neon_recording.VideoStream.height","title":"height  <code>property</code>","text":"<pre><code>height: int | None\n</code></pre> <p>Height of image in stream</p>"},{"location":"modules/#pupil_labs.neon_recording.VideoStream.ts","title":"ts  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ts = fields[int64](TIMESTAMP_FIELD_NAME)\n</code></pre> <p>The moment these data were recorded</p>"},{"location":"modules/#pupil_labs.neon_recording.VideoStream.width","title":"width  <code>property</code>","text":"<pre><code>width: int | None\n</code></pre> <p>Width of image in stream</p>"},{"location":"modules/#pupil_labs.neon_recording.WornStream","title":"WornStream","text":"<pre><code>WornStream(recording: NeonRecording)\n</code></pre> <p>               Bases: <code>Stream[WornRecord]</code>, <code>WornProps</code></p> <p>Worn (headset on/off) data</p> <p>Attributes:</p> <ul> <li> <code>ts</code>           \u2013            <p>The moment these data were recorded</p> </li> <li> <code>worn</code>           \u2013            <p>Worn</p> </li> </ul> Source code in <code>src/pupil_labs/neon_recording/stream/worn_stream.py</code> <pre><code>def __init__(self, recording: \"NeonRecording\"):\n    log.debug(\"NeonRecording: Loading worn data\")\n\n    worn_200hz_file = recording._rec_dir / \"worn_200hz.raw\"\n    time_200hz_file = recording._rec_dir / \"gaze_200hz.time\"\n\n    file_pairs = []\n    if worn_200hz_file.exists() and time_200hz_file.exists():\n        log.debug(\"NeonRecording: Using 200Hz worn data\")\n        file_pairs.append((worn_200hz_file, time_200hz_file))\n    else:\n        log.debug(\"NeonRecording: Using realtime worn data\")\n        file_pairs = find_sorted_multipart_files(recording._rec_dir, \"worn\")\n\n    data = load_multipart_data_time_pairs(file_pairs, np.dtype([(\"worn\", \"u1\")]))\n    super().__init__(\"worn\", recording, data.view(WornArray))\n</code></pre>"},{"location":"modules/#pupil_labs.neon_recording.WornStream.ts","title":"ts  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ts = fields[int64](TIMESTAMP_FIELD_NAME)\n</code></pre> <p>The moment these data were recorded</p>"},{"location":"modules/#pupil_labs.neon_recording.WornStream.worn","title":"worn  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>worn = fields[float64]('worn')\n</code></pre> <p>Worn</p>"},{"location":"modules/#pupil_labs.neon_recording.load","title":"load","text":"<pre><code>load(rec_dir_in: Union[Path, str]) -&gt; NeonRecording\n</code></pre> <p>Load a NeonRecording from a path</p> Source code in <code>src/pupil_labs/neon_recording/neon_recording.py</code> <pre><code>def load(rec_dir_in: Union[pathlib.Path, str]) -&gt; NeonRecording:\n    \"\"\"Load a NeonRecording from a path\"\"\"\n    return NeonRecording(rec_dir_in)\n</code></pre>"},{"location":"coverage/","title":"Coverage report","text":""}]}